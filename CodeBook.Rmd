---
title: "CodeBook"
author: "Aaron Cole"
date: "20 December 2015"
output: 
    html_document:
        toc: true
        toc_depth: 4
        theme: united
---

## Dataset information
* Dataset full name is "Human Activity Recognition Using Smartphones Dataset".
* The dataset folder is named "UCI HAR Dataset" and is located in the root of the repository.
* Information about the dataset can be found at [http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones](http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones).
* The dataset can be downloaded at [https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip](https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip)

## Assumptions
* Variable count and ordering is the same between the "X_test.txt" and "X_train.txt" files.
* Each line in the data files is one observation.
* There should be the same number of observations in each of the 3 data files for the "test" and "train" datasets.
* The "Inertial Signals" folder within the "test" and "train" folders can be ignored.
* We will match the converted variable names for the strings ".mean.." and ".std.." for the purpose of identifying the mean and standard deviation columns we are interested in keeping.

## Checks
* Once the "test" and "train" datasets have been joined, there should be exactly 10,299 observations.
* The "test" dataset should have 9 unique subjects.
* The "train" dataset should have 21 unique subjects.
* The joined dataset of 10,299 observations should have 30 unique subjects.

## Detailed functional description of the scripts

### run_analysis.R
1. When calling the run_analysis function three parameters can be supplied, all of which are logical and default to FALSE.
    + return\_tidy\_data is a flag to indicate if a dplyr tbl_df of the tidy data should be returned to the function caller.
    + re\_prepare is a flag to indicate if the raw data needs to be re-prepared and the prepare_data.csv file rebuilt.
    + re\_tidy is a flag to indicate if the prepared data need to be re-tidied and the tidy_data.csv file rebuilt.
```{r eval=FALSE}
run_analysis <- function(return_tidy_data = FALSE, re_prepare = FALSE, re_tidy = FALSE)
```
2. Load the libraries we'll be using.
```{r eval=FALSE}
# Load libraries.
library(dplyr, quietly = TRUE, verbose = FALSE, warn.conflicts = FALSE)
library(tidyr, quietly = TRUE, verbose = FALSE, warn.conflicts = FALSE)
```
3. Source the prepare and tidy scripts.
```{r eval=FALSE}
# Source scripts.
source("prepare_data.R")
source("tidy_data.R")
```
4. Setup filename variables.
```{r eval=FALSE}
# Setup the filenames.
filename_prepared_data <- "prepared_data.csv"
filename_tidy_data <- "tidy_data.csv" 
```
5. Check if the prepared and tidy data files exist already. If they do not exist, or if they need to be rebuilt then set the flag and output a message. If we are re-preparing the data then we should also re-tidy the newly prepared data.
```{r eval=FALSE}
# Check if the prepared data file exists.
if(file.exists(filename_prepared_data) == FALSE | re_prepare == TRUE) {
    re_prepare = TRUE
    message("Info: File prepared_data.csv will be rebuilt.")
}

# Check if the tidy data file exists.
if(file.exists(filename_tidy_data) == FALSE | re_tidy == TRUE) {
    re_tidy = TRUE
    message("Info: File tidy_data.csv will be rebuilt.")
}

# If we are re-preparing, then we should also re-tidy with the newly 
# prepared data
if(re_prepare == TRUE & re_tidy == FALSE) {
    re_tidy = TRUE
    message("Info: File tidy_data.csv will therefore also be rebuilt.")
}
```
6. Preparing (and re-preparing) the data.
    + Make two calls to the prepare_data function, passing "test" then "train".
    + Row bind the results.
    + Perform checks on the prepared data.
    + Write the prepared data out to file "prepared_data.CSV".
    + Print completion message.
```{r eval=FALSE}
if(re_prepare) {
    # Prepare and load the data.
    test_data <- prepare_data("test")
    train_data <- prepare_data("train")
    
    # Join the datasets.
    prepared_data <- bind_rows(test_data, train_data)
    
    # Check there are 10,299 observations.
    if(nrow(prepared_data) != 10299) {
        stop("Observations count is not 10,299.")
    }
    
    # Write a CSV with the prepared data, ready for further processing.
    write.csv(prepared_data, file.path(filename_prepared_data), 
              row.names = FALSE)
    
    message("Info: File prepared_data.csv has been rebuilt.")
}
```
7. Tidying (and re-tidying) the data.
    + Call the tidy_data function, passing the prepared data read from CSV.
    + Write the tidied data out to file "tidy_data.CSV".
    + Print completion message.
```{r eval=FALSE}
if(re_tidy) {
    # Read and tidy the prepared data.
    tidy_df <- tidy_data(tbl_df(read.csv(filename_prepared_data)))
    
    # Write a CSV with the tidy data.
    write.csv(tidy_df, file.path(filename_tidy_data), row.names = FALSE)
    
    message("Info: File tidy_data.csv has been rebuilt.")
}
```
8. Check if any processing was done and print messages if not.
```{r eval=FALSE}
if(re_prepare == FALSE & re_tidy == FALSE) {
    message("Warning: No processing was performed.")
    message("Info: prepared_data.csv and tidy_data.csv already exist.")
    message("Info: Set parameter re_prepare = TRUE to re-prepare data.")
    message("Info: Set parameter re_tidy = TRUE to re-tidy data.")
}
```
9. If return\_tidy\_data is TRUE, then read the tidy data from CSV and return it to the function caller.
```{r eval=FALSE}
if(return_tidy_data) {
    cols = c(subject = "integer", 
             activity = "character",
             domain = "character",
             signal_type = "character",
             signal_source = "character",
             signal_form = "character", 
             calculation = "character", 
             axis = "character", 
             value = "double")
    return(tbl_df(read.csv(filename_tidy_data,
                           colClasses = cols)))
}
```

### prepare_data.R
1. When calling the prepare_data function a single parameter must be supplied with a value of either "test" or "train", to indicate the dataset to work with.
```{r eval=FALSE}
# Input parameter should be either "train" or "test".
prepare_data <- function(dataset)
```
2. Validate the dataset parameter value.
```{r eval=FALSE}
# Validate the dataset to be worked with.
if(dataset %in% c("test", "train") == FALSE) {
    stop("Parameter \"dataset\" must be either \"test\" or \"train\".")
}
```
3. Setup variables.
```{r eval=FALSE}
# Variable setup.
dataset_folder <- "UCI HAR Dataset"
subject_values <- NULL
activity_values <- NULL
main_data <- NULL
```
4. Read the relevant files based on the value of the "dataset" parameter. Whichever case, the data is loaded into the same variables for further processing.
```{r eval=FALSE}
    # Read the relevant files.
    if(dataset == "test") {
        # dataset is "test".
        subject_values <- tbl_df(read.table(file.path(dataset_folder, 
                                                      "test", 
                                                      "subject_test.txt")))
        activity_values <- tbl_df(read.table(file.path(dataset_folder, 
                                                       "test", 
                                                       "y_test.txt")))
        main_data <- tbl_df(read.table(file.path(dataset_folder, 
                                                 "test", 
                                                 "X_test.txt")))
    } else {
        # dataset is "train".
        subject_values <- tbl_df(read.table(file.path(dataset_folder, 
                                                      "train", 
                                                      "subject_train.txt")))
        activity_values <- tbl_df(read.table(file.path(dataset_folder, 
                                                       "train", 
                                                       "y_train.txt")))
        main_data <- tbl_df(read.table(file.path(dataset_folder, 
                                                 "train", 
                                                 "X_train.txt")))
    }
```
5. Perform checks on the loaded data.
```{r eval=FALSE}
# Check for the correct number of unique subject values.
if(dataset == "test") {
    # dataset is "test".
    if(subject_values %>% distinct() %>% count() != 9) {
        stop("The count of unique subjects is not the expected value of 9.")
    }
} else {
    # dataset is "train".
    if(subject_values %>% distinct() %>% count() != 21) {
        stop("The count of unique subjects is not the expected value of 21."
             )
    }
}

# Check that loaded datasets all have the same number of observations.
if(!identical(nrow(subject_values), nrow(activity_values), 
             nrow(main_data))) {
    stop("Datasets have different count of observations.")
}
```
6. Set column names.
```{r eval=FALSE}
# Set column names for the subject and activity values datasets.
colnames(subject_values) <- "subject"
colnames(activity_values) <- "activity_id"
```
7. Validate that the activity values are as expected. Then load the activity labels and set column names.
```{r eval=FALSE}
# Check that the unique activity values are within the range 1 to 6.
if(!all(distinct(activity_values)$activity_id %in% c(1,2,3,4,5,6))) {
    stop("The activity values are not within the range of 1 to 6.")
}

# Load the activity labels.
activity_labels <- tbl_df(read.table(file.path(dataset_folder,
                                               "activity_labels.txt")))

# Set column names for the activity labels dataset.
colnames(activity_labels) <- c("activity_id", "activity")
```
8. Join the activity values and their labels, then select only the labels and convert the column class.
```{r eval=FALSE}
# Join the activity values and labels datasets, then select only labels.
activity_values <- 
    activity_values %>% 
    left_join(activity_labels, by = "activity_id") %>%
    select(activity)

# Convert the activity column to a character vector.
activity_values$activity <- as.character(activity_values$activity)
```
9. Bind the columns of the subject and activity datasets. The resulting dataset will be joined to the main data later on.
```{r eval=FALSE}
# Join the subject and activity datasets.
subjects_and_activities <- bind_cols(subject_values, activity_values)
```
10. Load the variable labels and set column names.
```{r eval=FALSE}
# Load the variable labels.
variable_labels <- tbl_df(read.table(file.path(dataset_folder, 
                                               "features.txt")))

# Set variables dataset column names.
colnames(variable_labels) <- c("variable_id", "variable")
```
11. Check that the number of variable labels matches the number of columns in the main data.
```{r eval=FALSE}
# Check the number of variable labels (columns).
if(!identical(nrow(variable_labels), ncol(main_data))) {
    stop("Variable count mismatch between labels and data.")       
}
```
12. Convert the variable labels to a character vector. The raw variable labels contain invalid characters which can cause problems, so we use the make.names() function to convert the variable labels to valid names and store in a new variable, which we use to set the column names of the main data.
```{r eval=FALSE}
# Convert variable labels to character vector.
variable_labels <- as.character(variable_labels$variable)

valid_variable_labels <- make.names(variable_labels, unique = TRUE, 
                                    allow_ = TRUE)

# Set column main data column names.
colnames(main_data) <- valid_variable_labels
```
13. We match the converted variable names for the strings ".mean.." and ".std.." for the purpose of identifying the mean and standard deviation columns we are interested in keeping. We create a logical vector so we know the positions of the variables we want to keep.
```{r eval=FALSE}
# Get a list of the variables we need to work with, based on matching the
# list for ".mean.." and ".std..".
selected_variables <- as.logical(
    grepl(".mean..", valid_variable_labels, fixed = TRUE) + 
        grepl(".std..", valid_variable_labels, fixed = TRUE))
```
14. Create an integer vector of all the main data variable positions. Loop through the variable\_positions vector and check if the same position is TRUE in our selected\_variables logical vector. If TRUE, store the position value in a vector to be used to select only the required variables by position into our main\_data dataset.
```{r eval=FALSE}
# Create a vector of the column positions in the main data.
variable_positions <- as.integer(1:length(selected_variables))

# Create a vector with the column positions we need to select.
selected_positions <- NULL
for(i in variable_positions) {
    if(selected_variables[i] == TRUE) {
        selected_positions <- c(selected_positions, i)
    }
}

# Select only the required columns.
main_data <- select(main_data, selected_positions)
```
15. Now the main\_data dataset has only the necessary columns, we can join it with the subjects\_and\_activities dataset.  
```{r eval=FALSE}
# Join the subject and activity dataset with the main dataset.
main_data <- bind_cols(subjects_and_activities, main_data)
```
16. The data is now prepared and can be returned to the caller.
```{r eval=FALSE}
# Return the dataset.
return(main_data)
```

### tidy_data.R
1. When calling the tidy_data function we must supply the prepared data as a parameter.
```{r eval=FALSE}
# The prepared dataset must be supplied as a parameter.
tidy_data <- function(dataset)
```
2. The prepared data is "wide", we need it to be "long". Many of the columns contain multiple variables, we need to tidy the columns. We can use the gather() function from tidyr to gather up our columns. We gather up all columns, excluding subject and activity.
```{r eval=FALSE}
# Use tidyr's gather() function to make the data long rather than wide.
# Exclude the subject and activity columns from the operation, include 
# all other columns.
dataset <- dataset %>%
    gather(signal, value, everything(), -subject, -activity) %>%
```
3. Our new signal column now includes multiple variables, we need to use tidyr's separate() function to start separating out the variables into their own columns.
```{r eval=FALSE}    
# Separate the signal column, putting the calculation and axis part
# into a new column named calculation.
separate(signal, c("signal", "calculation"), extra = "merge") %>%
# Separate the axis value from the calculation column.
separate(calculation, c("calculation", "axis")) %>%
# Separate the domain (value t or f) from the signal column, based on
# separating at the first character, the value of that character going 
# into a new column called domain.
separate(signal, c("domain", "signal"), sep = 1)
```
4. Use the sub() command to match a string within our "signal" variable and then concatenate a "." at the end, ready for separating out. Use seperate() to create new variables for "signal\_type" and "signal\_source". The remaining value left in the "signal" variable will form the "signal\_form" variable.
```{r eval=FALSE}  
# Separate signal for body and gravity.
dataset$signal <- as.character(dataset$signal)
dataset$signal <- sub("Body", "body.", dataset$signal, fixed = TRUE)
dataset$signal <- sub("Gravity", "gravity.", dataset$signal, fixed = TRUE)
dataset <- dataset %>%
    separate(signal, c("signal_type", "signal"))

# Separate signal for accelerometer and gyroscope.
dataset$signal <- sub("Acc", "accelerometer.", dataset$signal, fixed = TRUE)
dataset$signal <- sub("Gyro", "gyroscope.", dataset$signal, fixed = TRUE)
dataset <- dataset %>%
    separate(signal, c("signal_source", "signal_form"))
```
5. Our variables are now tidy, we have one variable per column. Our rows are also tidy, as each row is one observation. Now we need to tidy up some of the values within our variables. 
    + We use a convention of having all our character variable values in lowercase.
    + We use a convention of setting missing/blank values to NA.
    + We rename the "domain" variables "t = time" and "f = freq".
```{r eval=FALSE}  
# Tidy up activity values.
dataset$activity <- as.character(dataset$activity)
dataset$activity[dataset$activity == "STANDING"] <- "standing"
dataset$activity[dataset$activity == "SITTING"] <- "sitting"
dataset$activity[dataset$activity == "LAYING"] <- "laying"
dataset$activity[dataset$activity == "WALKING"] <- "walking"
dataset$activity[dataset$activity == "WALKING_DOWNSTAIRS"] <- 
    "walking_downstairs"
dataset$activity[dataset$activity == "WALKING_UPSTAIRS"] <- 
    "walking_upstairs"

# Tidy up domain values.
dataset$domain <- as.character(dataset$domain)
dataset$domain[dataset$domain == "t"] <- "time"
dataset$domain[dataset$domain == "f"] <- "freq"

# Tidy up signal_source values.
dataset$signal_source <- as.character(dataset$signal_source)
dataset$signal_source[dataset$signal_source == "Bodyaccelerometer"] <- "bodyaccelerometer"
dataset$signal_source[dataset$signal_source == "Bodygyroscope"] <- "bodygyroscope"

# Tidy up signal_form values.
dataset$signal_form[dataset$signal_form == ""] <- NA
dataset$signal_form[dataset$signal_form == "Jerk"] <- "jerk"
dataset$signal_form[dataset$signal_form == "Mag"] <- "mag"
dataset$signal_form[dataset$signal_form == "JerkMag"] <- "jerkmag"

# Tidy up axis values.
dataset$axis <- as.character(dataset$axis)
dataset$axis[dataset$axis == "X"] <- "x"
dataset$axis[dataset$axis == "Y"] <- "y"
dataset$axis[dataset$axis == "Z"] <- "z"

# Set blank axis values to NA.
dataset$axis[dataset$axis == ""] <- NA
```
6. Use dplyr's arrange() function to order our data by our columns from left to right.
```{r eval=FALSE}  
    # Arrange the dataset.
    dataset <- arrange(dataset, subject, activity, domain, signal_type, 
                       signal_source, signal_form, calculation, axis, value)
```
7. Use dplyr's group_by() function to group our columns from left to right, excluding grouping on value.
```{r eval=FALSE}  
    # Setup groupings.
    dataset <- group_by(dataset, subject, activity, domain, signal_type, 
                        signal_source, signal_form, calculation, axis)
```
8. Use dplyr's summarise() function to summarise the mean of value for our groups, returning the result in a "mean_value" column.
```{r eval=FALSE}  
    # Summarise mean of the value by groupings.
    summary_dataset <- summarise(dataset, mean_value = mean(value))
```
9. The data is now tidy, grouped and summarised using mean(value). Return the tidy date to the caller.
```{r eval=FALSE}  
    # Return the summary dataset.
    return(summary_dataset)
```

#### Output variable descriptions
The output data is grouped with the following heirarchy.

* subject > activity > domain > signal\_type > signa\l_source > signal_form > calculation > axis

Variable | Class | Description
---------|-------|------------
subject | int | The subject identifier from 1 to 30.
activity | chr | The activity type from a list of 6 options of "laying", "sitting", "standing", "walking", "walking\_downstairs", "walking\_upstairs".
domain | chr | Domain signal type, either "time" for time or "freq" for frequency.
signal\_type | chr | The acceleration signal type, either "body" or "gravity".
signal\_source | chr | The source of the signal, either "accelerometer", "bodyaccelerometer", "bodygyroscope" or "gyroscope". Note that the string "body" was featured twice in some of the messy variable names. For these variables we have used the first "body" for the "signal\_type" variable and the second "body" has been left as part of this "signal\_source" variable value.
signal\_form | chr | The signal form, either "jerk", "mag", "jerkmag" or NA.
calculation | chr | The calculation performed, either "mean" for the mean or "std" for the standard deviation.
axis | chr | The signal axis, if any, either "x", "y", "z" or NA.
mean_value | dbl | The mean value of the measurement.